{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bc4a95a6dd4fca9cb8deb9b3350e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Upload your model and data</h3>'), FileUpload(value={}, accept='.keras', descri‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import io\n",
    "from keras.models import load_model\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Upload widgets\n",
    "model_upload = widgets.FileUpload(accept='.keras', multiple=False, description='Upload Model (.keras)')\n",
    "scaler_upload = widgets.FileUpload(accept='.pkl', multiple=False, description='Upload Scaler (.pkl)')\n",
    "feature_upload = widgets.FileUpload(accept='.pkl', multiple=False, description='Upload Features (.pkl)')\n",
    "data_upload = widgets.FileUpload(accept='.csv', multiple=False, description='Upload Data (.csv)')\n",
    "run_button = widgets.Button(description=\"Run Model\", button_style='success')\n",
    "output = widgets.Output()\n",
    "\n",
    "# Global holders\n",
    "model = None\n",
    "scaler = None\n",
    "feature_columns = None\n",
    "\n",
    "# File saving function\n",
    "def save_upload(upload_widget, filename):\n",
    "    content = list(upload_widget.value.values())[0]['content']\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Load uploaded files\n",
    "def load_all_files():\n",
    "    global model, scaler, feature_columns\n",
    "\n",
    "    try:\n",
    "        save_upload(model_upload, 'uploaded_model.keras')\n",
    "        model = load_model('uploaded_model.keras')\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        save_upload(scaler_upload, 'uploaded_scaler.pkl')\n",
    "        scaler = joblib.load('uploaded_scaler.pkl')\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"‚ùå Error loading scaler: {e}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        save_upload(feature_upload, 'uploaded_features.pkl')\n",
    "        feature_columns = joblib.load('uploaded_features.pkl')\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(f\"‚ùå Error loading features: {e}\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Data cleaner\n",
    "def clean_and_process_data(file_obj):\n",
    "    df = pd.read_csv(file_obj, encoding='ISO-8859-1')\n",
    "    df = df.drop(df.index[0:2]).reset_index(drop=True)\n",
    "    mean_idx = df[df['Raw-Pleth#1'] == 'Mean'].index\n",
    "    drop_idx = set(mean_idx) | set(mean_idx + 1)\n",
    "    df = df.drop(drop_idx, errors='ignore').reset_index(drop=True)\n",
    "    df = df.replace({'‚àí': '-'}, regex=True)\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df = df.applymap(lambda x: x if str(x).replace('.', '', 1).replace('-', '', 1).isdigit() else None)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Prediction function\n",
    "def predict_and_filter(df):\n",
    "    df_clean = df.select_dtypes(include=[float, int]).dropna(axis=1, how='all')\n",
    "    for col in feature_columns:\n",
    "        if col not in df_clean.columns:\n",
    "            df_clean[col] = 0\n",
    "    df_clean = df_clean[feature_columns]\n",
    "    X_scaled = scaler.transform(df_clean)\n",
    "    y_pred = (model.predict(X_scaled) > 0.5).astype(int).flatten()\n",
    "    df['deleted_flag'] = y_pred\n",
    "    kept_df = df[df['deleted_flag'] == 0]\n",
    "    return kept_df\n",
    "\n",
    "# Button action\n",
    "def on_run_clicked(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        if not (model_upload.value and scaler_upload.value and feature_upload.value and data_upload.value):\n",
    "            print(\"‚ùó Please upload all required files before running.\")\n",
    "            return\n",
    "\n",
    "        print(\"‚è≥ Loading model, scaler, and features...\")\n",
    "        if not load_all_files():\n",
    "            return\n",
    "\n",
    "        print(\"‚úÖ Files loaded. Processing data...\")\n",
    "\n",
    "        file_obj = list(data_upload.value.values())[0]['content']\n",
    "        df = clean_and_process_data(io.BytesIO(file_obj))\n",
    "        result = predict_and_filter(df)\n",
    "\n",
    "        print(f\"‚úÖ Processing complete. Rows kept: {len(result)}\")\n",
    "        result.to_csv(\"cleaned_output.csv\", index=False)\n",
    "        display(result.head())\n",
    "        print(\"üìÅ Saved to: cleaned_output.csv\")\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "\n",
    "# Display GUI\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Upload your model and data</h3>\"),\n",
    "    model_upload,\n",
    "    scaler_upload,\n",
    "    feature_upload,\n",
    "    data_upload,\n",
    "    run_button,\n",
    "    output\n",
    "]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
